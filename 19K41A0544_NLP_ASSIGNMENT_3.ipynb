{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**19K41A0544** **ASSIGNMENT**-**3**"
      ],
      "metadata": {
        "id": "A4zNJZne34qE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\n",
        "\n",
        "Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\n",
        "\n",
        "QUESTIONS:\n",
        "\n",
        "Convert the above paragraph into vectors using:\n",
        "\n",
        "i) Word2vec\n",
        "\n",
        "ii) USE\n",
        "\n",
        "iii) ELMO\n",
        "\n",
        "iv) GP2\n",
        "\n",
        "v) Sentence-BERT\n",
        "\n",
        "Find named entities (NER) for the above paragraph?\n",
        "\n",
        "Find similar sentences (repeated sentences) from the above paragraph? (Cosine Similarity, use BERT to encode)\n",
        "Explain POS tagging with HMM? Tag POS for the above paragraph?"
      ],
      "metadata": {
        "id": "KRqOsUYG9b_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning the given paragraph to a variable\n",
        "\n",
        "para = '''A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\n",
        "Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\n",
        "'''\n",
        "para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "AjOp90r59qKm",
        "outputId": "e23ad559-5ff2-4cff-c82d-b6b1bbfd519a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.\\nParagraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the paragraph to vectors:"
      ],
      "metadata": {
        "id": "wxPhtttO-Bfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required packages\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import word2vec\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ili0-Bb-DVz",
        "outputId": "27a7c88c-693d-46f5-ace4-2cf7a289b277"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#code to convert paragraph to sentences\n",
        "\n",
        "def essay_to_sentences(paragraph):\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    raw_sentences = tokenizer.tokenize(paragraph.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append((raw_sentence))\n",
        "    return sentences\n",
        "\n",
        "sentences=essay_to_sentences(para)\n",
        "\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh6lWRyn-NGB",
        "outputId": "79f28be2-0058-425c-e9b1-0cc0173c94c1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic.',\n",
              " 'Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs.',\n",
              " 'This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.',\n",
              " 'Paragraphs can contain many different kinds of information.',\n",
              " 'A paragraph could contain a series of brief examples or a single long illustration of a general point.',\n",
              " 'It might describe a place, character, or process; narrate a series of events; compare or contrast two or more things; classify items into categories; or describe causes and effects.',\n",
              " 'Regardless of the kind of information they contain, all paragraphs share certain characteristics.',\n",
              " 'One of the most important of these is a topic sentence.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec**"
      ],
      "metadata": {
        "id": "elpCMNd7-VjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "wordvecs=[nltk.word_tokenize(s) for s in sentences]\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stops_words=list(set(stopwords.words(\"english\")))\n",
        "\n",
        "for i in wordvecs:\n",
        "  for j in i:\n",
        "    if j in stops_words:\n",
        "      i.remove(j)\n",
        "    elif len(j)==1:\n",
        "      i.remove(j)\n",
        "\n",
        "model=Word2Vec(wordvecs,min_count=1,size = 32)\n",
        "\n",
        "\n",
        "model.wv['organized']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AdaXSMJ_ewL",
        "outputId": "376bf52b-6fe0-43c7-93aa-3b8fe79fd5d0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-6.8560117e-03, -8.5748369e-03, -1.3185214e-03, -1.3907707e-02,\n",
              "        9.9190995e-03, -7.7170711e-03, -1.6863807e-05,  3.0846414e-04,\n",
              "        7.1714772e-03, -1.3133104e-02, -1.1578677e-02, -7.6462156e-03,\n",
              "        1.1698958e-02, -4.3718363e-03,  6.0851569e-03,  1.3255417e-02,\n",
              "        9.0720560e-03, -1.1617768e-02,  6.1195241e-03, -5.4051559e-03,\n",
              "        2.6332249e-04,  6.2929993e-03,  1.2439562e-02, -6.0021030e-03,\n",
              "       -1.3245103e-03,  1.3117938e-02, -1.6948220e-03,  1.0812423e-02,\n",
              "       -8.9144371e-03, -3.4188782e-03, -6.0715317e-04, -4.9191050e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**USE**"
      ],
      "metadata": {
        "id": "eN9l3da4A2bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "vect=hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "#converting to vectors\n",
        "res_vectors=vect(sentences)\n",
        "print(res_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw-ZUsxgA35W",
        "outputId": "6a4bb078-e516-4d89-cde2-98210cee4afc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"StatefulPartitionedCall_3:0\", shape=(None, 512), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape= \",res_vectors[0].shape)\n",
        "\n",
        "#each sentence is converted into vector having 512 values\n",
        "\n",
        "print(\"The sentence: \",sentences[0],\"\\n is converted as : \\n{}\".format(res_vectors[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zirm3kABE8p",
        "outputId": "f8accc08-40f8-476c-c3e3-669f927adb08"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape=  (512,)\n",
            "The sentence:  A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " is converted as : \n",
            "Tensor(\"strided_slice_5:0\", shape=(512,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ELMO**"
      ],
      "metadata": {
        "id": "Nag-m0lHBJdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the ELMO Model\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "#1024 sized vectors\n",
        "elmo=hub.Module(\"https://tfhub.dev/google/elmo/3\",trainable=True)\n",
        "embeddings=elmo(\n",
        "    sentences,\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"elmo\"]\n",
        "init=tf.initialize_all_variables()\n",
        "sess=tf.Session()\n",
        "sess.run(init)\n",
        "print(\"\\n\\n\")\n",
        "print(sess.run(embeddings[0]))\n",
        "print(\"shape=\",embeddings[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRRK8ceBBKi7",
        "outputId": "b57367af-8c7f-477c-8ef0-31655389f1e0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "[[ 0.29287004 -0.14378013 -0.32574052 ... -0.39559263 -0.35758853\n",
            "  -0.03588088]\n",
            " [-0.59441584  0.09640743  0.50537694 ...  0.22031914  0.269769\n",
            "   0.46307266]\n",
            " [-0.1708326  -0.18744111 -0.27626696 ... -0.67550904  0.25389987\n",
            "   0.6540271 ]\n",
            " ...\n",
            " [-0.0284084  -0.04353216  0.04130162 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]\n",
            " [-0.0284084  -0.04353216  0.04130162 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]\n",
            " [-0.0284084  -0.04353216  0.04130162 ...  0.02583168 -0.01429836\n",
            "  -0.01650422]]\n",
            "shape= (32, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GP2**"
      ],
      "metadata": {
        "id": "izmC-RqFBSQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnobXMDRBuy1",
        "outputId": "a18226b6-6be5-4320-f80f-307d465a0362"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "gptokenizer=transformers.GPT2Tokenizer.from_pretrained('gpt2-large')\n",
        "model=transformers.GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
        "res_vectors=gptokenizer.encode(para,add_special_tokens=False,return_tensors=\"pt\")\n",
        "print(\"shape=\",res_vectors.shape)\n",
        "res_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sJqP15wBTUv",
        "outputId": "a9310f8e-fa06-4e68-c742-ec87851c2fda"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= torch.Size([1, 173])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   32,  7322,   318,   257,  2168,   286, 13439,   326,   389,  8389,\n",
              "           290, 24870,    11,   290,   389,   477,  3519,   284,   257,  2060,\n",
              "          7243,    13, 16699,   790,  3704,   286,  3597,   345,   466,   326,\n",
              "           318,  2392,   621,   257,  1178, 13439,   815,   307,  8389,   656,\n",
              "         23549,    13,   770,   318,   780, 23549,   905,   257,  9173,   810,\n",
              "           262, 45944,  3279,   286,   281, 14268,  2221,   290,   886,    11,\n",
              "           290,  4145,  1037,   262,  9173,   766,   262,  4009,   286,   262,\n",
              "         14268,   290, 13180,   663,  1388,  2173,    13,   198, 10044,  6111,\n",
              "            82,   460,  3994,   867,  1180,  6982,   286,  1321,    13,   317,\n",
              "          7322,   714,  3994,   257,  2168,   286,  4506,  6096,   393,   257,\n",
              "          2060,   890, 20936,   286,   257,  2276,   966,    13,   632,  1244,\n",
              "          6901,   257,  1295,    11,  2095,    11,   393,  1429,    26,  6664,\n",
              "           378,   257,  2168,   286,  2995,    26,  8996,   393,  6273,   734,\n",
              "           393,   517,  1243,    26, 36509,  3709,   656,  9376,    26,   393,\n",
              "          6901,  5640,   290,  3048,    13, 22250,   286,   262,  1611,   286,\n",
              "          1321,   484,  3994,    11,   477, 23549,  2648,  1728,  9695,    13,\n",
              "          1881,   286,   262,   749,  1593,   286,   777,   318,   257,  7243,\n",
              "          6827,    13,   198]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence**-**BERT**"
      ],
      "metadata": {
        "id": "WiqO6wkGCWfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
        "embeddings=bert(sentences)\n",
        "print(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx2iUdOQCXMf",
        "outputId": "dd99a8c4-da62-4ff0-9a5d-7f51ffb7ad25"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"keras_layer_1/StatefulPartitionedCall:0\", shape=(None, 128), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape=\",embeddings[0].shape)\n",
        "#each sentence is converted into vector having 128 values\n",
        "print(\"The sentence in the paragraph: \",sentences[0],\"\\n is converted into vector  as : \\n{}\".format(embeddings[0]))\n",
        "shape= (128,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frzqHSKNCgfT",
        "outputId": "cc8eeac0-f598-4d4a-e819-de530a110dfe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape= (128,)\n",
            "The sentence in the paragraph:  A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " is converted into vector  as : \n",
            "Tensor(\"strided_slice_9:0\", shape=(128,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Find named entities (NER) for the above paragraph?"
      ],
      "metadata": {
        "id": "mcve6xHLCk_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "ner=spacy.load('en_core_web_sm')\n",
        "res=ner(para)\n",
        "\n",
        "for word in res.ents:\n",
        "  print(word.text,word.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ems2bmcCnWj",
        "outputId": "e34f9e4e-e991-4351-a96c-d3968e422d72"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "two CARDINAL\n",
            "One CARDINAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.explain('GPE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WMw3DSJRCtos",
        "outputId": "13919c64-7f6b-423b-f604-5be750b395c7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Countries, cities, states'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(res,style=\"ent\",jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AR5SnAM7Cwnz",
        "outputId": "10f235ca-091c-4d56-929c-43630ab23866"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. This is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points.</br>Paragraphs can contain many different kinds of information. A paragraph could contain a series of brief examples or a single long illustration of a general point. It might describe a place, character, or process; narrate a series of events; compare or contrast \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " or more things; classify items into categories; or describe causes and effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    One\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " of the most important of these is a topic sentence.</br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find similar sentences (repeated sentences) from the above paragraph? (Cosine Similarity, use BERT to encode)"
      ],
      "metadata": {
        "id": "cjKC2rFbC2th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX0ZpmYrDD2z",
        "outputId": "9c5d35a0-212e-4546-e4e5-70f56562f336"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.13.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.10.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.12.1+cu113)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.23.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "metadata": {
        "id": "Uwc0B63OC38E"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using BERT to Encode\n",
        "se_embeddings = sbert_model.encode(sentences)\n",
        "q1_vec= sbert_model.encode(sentences[0])\n",
        "\n",
        "#cosine similarity function\n",
        "#identifies similarity between 2 sentences\n",
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
        "\n",
        "for sent in sentences:\n",
        "  sim = cosine(q1_vec, sbert_model.encode([sent])[0])\n",
        "  #if similarity ==1 => repeated sentence\n",
        "  #if similarity > 0.6 => similar sentence\n",
        "  if sim>0.6:\n",
        "    print(\"Sentence1 =\",sentences[0],\"\\n \\nSentence2=\", sent, \"\\n\\nsimilarity = \", sim,end=\"\\n ----------------------------- \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYlZYs_RDVgn",
        "outputId": "e354706c-99a8-47f7-c6f9-4c6b44812b0f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            "\n",
            "similarity =  1.0\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= Almost every piece of writing you do that is longer than a few sentences should be organized into paragraphs. \n",
            "\n",
            "similarity =  0.6477537\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= A paragraph could contain a series of brief examples or a single long illustration of a general point. \n",
            "\n",
            "similarity =  0.69272894\n",
            " ----------------------------- \n",
            "Sentence1 = A paragraph is a series of sentences that are organized and coherent, and are all related to a single topic. \n",
            " \n",
            "Sentence2= Regardless of the kind of information they contain, all paragraphs share certain characteristics. \n",
            "\n",
            "similarity =  0.78738403\n",
            " ----------------------------- \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "parts of speech tagging with hidden markov model(hmm):\n",
        "\n",
        "Hidden Markov Model based algorithm is used to tag the words. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word.\n",
        "\n",
        "To every word w, assign the tag t that maximises the likelihood P(t/w). Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t)."
      ],
      "metadata": {
        "id": "BVLWUbgZDupH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WenrOi0Dx62",
        "outputId": "2a637f6a-fc59-4b23-fe96-2f6505e4fc65"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"A paragraph is a series of sentences that are organized and coherent, and are all  related  to  a  single  topic.  Almost  every  piece  of  writing you  do  that  is longer  than  a  few  sentences  should  be  organized  into paragraphs.  This  is because paragraphs show a reader where the subdivisions of an essay begin and end, and thus help the reader see the organization of the essay and grasp its main points. Paragraphs can  contain  many  different  kinds  of  information. A paragraph could  contain  a  series  of  brief  examples  or  a  single  long illustration  of  a general  point.  It  might  describe  a  place,  character,  or process;  narrate  a series of events; compare or contrast two or more things; classify items into categories;  or  describe  causes  and  effects. Regardless of the kind of information they contain, all paragraphs share certain characteristics. One of the most important of these is a topic sentence.\"\n",
        "result = word_tokenize(text)"
      ],
      "metadata": {
        "id": "hiZFZToMD3uB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos = nltk.pos_tag(result)\n",
        "print(pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKh2OuZXD_Nr",
        "outputId": "d801dad8-b020-43fe-f017-234c4116ed7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('A', 'DT'), ('paragraph', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('series', 'NN'), ('of', 'IN'), ('sentences', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('organized', 'VBN'), ('and', 'CC'), ('coherent', 'NN'), (',', ','), ('and', 'CC'), ('are', 'VBP'), ('all', 'DT'), ('related', 'VBN'), ('to', 'TO'), ('a', 'DT'), ('single', 'JJ'), ('topic', 'NN'), ('.', '.'), ('Almost', 'CC'), ('every', 'DT'), ('piece', 'NN'), ('of', 'IN'), ('writing', 'VBG'), ('you', 'PRP'), ('do', 'VBP'), ('that', 'DT'), ('is', 'VBZ'), ('longer', 'JJR'), ('than', 'IN'), ('a', 'DT'), ('few', 'JJ'), ('sentences', 'NNS'), ('should', 'MD'), ('be', 'VB'), ('organized', 'VBN'), ('into', 'IN'), ('paragraphs', 'NN'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('because', 'IN'), ('paragraphs', 'NN'), ('show', 'VBP'), ('a', 'DT'), ('reader', 'NN'), ('where', 'WRB'), ('the', 'DT'), ('subdivisions', 'NNS'), ('of', 'IN'), ('an', 'DT'), ('essay', 'NN'), ('begin', 'NN'), ('and', 'CC'), ('end', 'NN'), (',', ','), ('and', 'CC'), ('thus', 'RB'), ('help', 'VB'), ('the', 'DT'), ('reader', 'NN'), ('see', 'VBP'), ('the', 'DT'), ('organization', 'NN'), ('of', 'IN'), ('the', 'DT'), ('essay', 'NN'), ('and', 'CC'), ('grasp', 'VB'), ('its', 'PRP$'), ('main', 'JJ'), ('points', 'NNS'), ('.', '.'), ('Paragraphs', 'NNP'), ('can', 'MD'), ('contain', 'VB'), ('many', 'JJ'), ('different', 'JJ'), ('kinds', 'NNS'), ('of', 'IN'), ('information', 'NN'), ('.', '.'), ('A', 'DT'), ('paragraph', 'NN'), ('could', 'MD'), ('contain', 'VB'), ('a', 'DT'), ('series', 'NN'), ('of', 'IN'), ('brief', 'JJ'), ('examples', 'NNS'), ('or', 'CC'), ('a', 'DT'), ('single', 'JJ'), ('long', 'JJ'), ('illustration', 'NN'), ('of', 'IN'), ('a', 'DT'), ('general', 'JJ'), ('point', 'NN'), ('.', '.'), ('It', 'PRP'), ('might', 'MD'), ('describe', 'VB'), ('a', 'DT'), ('place', 'NN'), (',', ','), ('character', 'NN'), (',', ','), ('or', 'CC'), ('process', 'NN'), (';', ':'), ('narrate', 'CC'), ('a', 'DT'), ('series', 'NN'), ('of', 'IN'), ('events', 'NNS'), (';', ':'), ('compare', 'NN'), ('or', 'CC'), ('contrast', 'NN'), ('two', 'CD'), ('or', 'CC'), ('more', 'JJR'), ('things', 'NNS'), (';', ':'), ('classify', 'VB'), ('items', 'NNS'), ('into', 'IN'), ('categories', 'NNS'), (';', ':'), ('or', 'CC'), ('describe', 'VB'), ('causes', 'NNS'), ('and', 'CC'), ('effects', 'NNS'), ('.', '.'), ('Regardless', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('kind', 'NN'), ('of', 'IN'), ('information', 'NN'), ('they', 'PRP'), ('contain', 'VBP'), (',', ','), ('all', 'DT'), ('paragraphs', 'NNS'), ('share', 'NN'), ('certain', 'JJ'), ('characteristics', 'NNS'), ('.', '.'), ('One', 'CD'), ('of', 'IN'), ('the', 'DT'), ('most', 'RBS'), ('important', 'JJ'), ('of', 'IN'), ('these', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('topic', 'JJ'), ('sentence', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}